# app.py
from flask import Flask, render_template, request, Response, jsonify
import google.generativeai as genai
import os
import json
from dotenv import load_dotenv

# Load environment variables from a .env file
load_dotenv()

app = Flask(__name__)

# --- Configuration ---
try:
    # Get API key from environment variables
    API_KEY = os.getenv("GOOGLE_API_KEY")
    if not API_KEY:
        raise ValueError("GOOGLE_API_KEY not found in environment variables or .env file.")
    
    genai.configure(api_key=API_KEY)
    
    # Initialize the model
    model = genai.GenerativeModel('gemini-2.5-flash')
    print("‚úÖ Google Gemini API configured successfully.")

except Exception as e:
    print(f"‚ùå FATAL ERROR: Could not configure Google Gemini API. {e}")
    # Exit if the API key is not configured, as the app is unusable.
    exit()

# --- System Prompts ---
SYSTEM_PROMPTS = {
    'en': """You are Kisan Sathi, an expert agricultural assistant helping Indian farmers. 
    Provide practical, accurate advice on:
    - Crop cultivation and farming techniques
    - Pest and disease management
    - Soil health and fertilizers
    - Weather-related farming decisions
    - Government schemes for farmers
    - Market prices and crop selling
    
    Keep responses concise, practical, and easy to understand. 
    **Use Markdown for formatting, including headings, bold text, and bulleted/numbered lists to structure your answers.**
    Always be respectful and supportive.""",
    
    'hi': """‡§Ü‡§™ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§∏‡§æ‡§•‡•Ä ‡§π‡•à‡§Ç, ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§è‡§ï ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§ï‡•É‡§∑‡§ø ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à‡§Ç‡•§
    ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§µ‡§ø‡§∑‡§Ø‡•ã‡§Ç ‡§™‡§∞ ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï, ‡§∏‡§ü‡•Ä‡§ï ‡§∏‡§≤‡§æ‡§π ‡§¶‡•á‡§Ç:
    - ‡§´‡§∏‡§≤ ‡§ï‡•Ä ‡§ñ‡•á‡§§‡•Ä ‡§î‡§∞ ‡§ï‡•É‡§∑‡§ø ‡§§‡§ï‡§®‡•Ä‡§ï
    - ‡§ï‡•Ä‡§ü ‡§î‡§∞ ‡§∞‡•ã‡§ó ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®
    - ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§î‡§∞ ‡§â‡§∞‡•ç‡§µ‡§∞‡§ï
    - ‡§Æ‡•å‡§∏‡§Æ ‡§∏‡•á ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§ñ‡•á‡§§‡•Ä ‡§ï‡•á ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø
    - ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Ç
    - ‡§¨‡§æ‡§ú‡§æ‡§∞ ‡§Æ‡•Ç‡§≤‡•ç‡§Ø ‡§î‡§∞ ‡§´‡§∏‡§≤ ‡§¨‡§ø‡§ï‡•ç‡§∞‡•Ä
    
    ‡§ú‡§µ‡§æ‡§¨ ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§, ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§î‡§∞ ‡§∏‡§Æ‡§ù‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Ü‡§∏‡§æ‡§® ‡§∞‡§ñ‡•á‡§Ç‡•§
    **‡§Ö‡§™‡§®‡•á ‡§â‡§§‡•ç‡§§‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Ç‡§∞‡§ö‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•á‡§°‡§ø‡§Ç‡§ó, ‡§¨‡•ã‡§≤‡•ç‡§° ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§î‡§∞ ‡§¨‡•Å‡§≤‡•á‡§ü‡•á‡§°/‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï‡§ø‡§§ ‡§∏‡•Ç‡§ö‡§ø‡§Ø‡•ã‡§Ç ‡§∏‡§π‡§ø‡§§ ‡§´‡§º‡•â‡§∞‡•ç‡§Æ‡•á‡§ü‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§æ‡§∞‡•ç‡§ï‡§°‡§æ‡§â‡§® ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§**
    ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡§Æ‡•ç‡§Æ‡§æ‡§®‡§ú‡§®‡§ï ‡§î‡§∞ ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§∞‡§π‡•á‡§Ç‡•§""",
    
    'mr': """‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§ï‡§ø‡§∏‡§æ‡§® ‡§∏‡§æ‡§•‡•Ä ‡§Ü‡§π‡§æ‡§§, ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§∂‡•á‡§§‡§ï‡§±‡•ç‡§Ø‡§æ‡§Ç‡§®‡§æ ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡§£‡§æ‡§∞‡•á ‡§§‡§ú‡•ç‡§û ‡§ï‡•É‡§∑‡•Ä ‡§∏‡§π‡§æ‡§Ø‡•ç‡§Ø‡§ï ‡§Ü‡§π‡§æ‡§§.
    ‡§ñ‡§æ‡§≤‡•Ä‡§≤ ‡§µ‡§ø‡§∑‡§Ø‡§æ‡§Ç‡§µ‡§∞ ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï, ‡§Ö‡§ö‡•Ç‡§ï ‡§∏‡§≤‡•ç‡§≤‡§æ ‡§¶‡•ç‡§Ø‡§æ:
    - ‡§™‡•Ä‡§ï ‡§≤‡§æ‡§ó‡§µ‡§° ‡§Ü‡§£‡§ø ‡§∂‡•á‡§§‡•Ä ‡§§‡§Ç‡§§‡•ç‡§∞
    - ‡§ï‡•Ä‡§ü‡§ï ‡§î‡§∞ ‡§∞‡•ã‡§ó ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§®
    - ‡§Æ‡§æ‡§§‡•Ä‡§ö‡•á ‡§Ü‡§∞‡•ã‡§ó‡•ç‡§Ø ‡§Ü‡§£‡§ø ‡§ñ‡§§‡•á
    - ‡§π‡§µ‡§æ‡§Æ‡§æ‡§®‡§æ‡§∂‡•Ä ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§∂‡•á‡§§‡•Ä ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø
    - ‡§∂‡•á‡§§‡§ï‡§±‡•ç‡§Ø‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ
    - ‡§¨‡§æ‡§ú‡§æ‡§∞ ‡§ï‡§ø‡§Ç‡§Æ‡§§ ‡§Ü‡§£‡§ø ‡§™‡•Ä‡§ï ‡§µ‡§ø‡§ï‡•ç‡§∞‡•Ä
    
    ‡§â‡§§‡•ç‡§§‡§∞‡•á ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§, ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§Ü‡§£‡§ø ‡§∏‡§Æ‡§ú‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§∏‡•ã‡§™‡•Ä ‡§†‡•á‡§µ‡§æ. 
    **‡§§‡•Å‡§Æ‡§ö‡•Ä ‡§â‡§§‡•ç‡§§‡§∞‡•á ‡§∏‡§Ç‡§∞‡§ö‡§ø‡§§ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Æ‡§•‡§≥‡•á, ‡§†‡§≥‡§ï ‡§Æ‡§ú‡§ï‡•Ç‡§∞ ‡§Ü‡§£‡§ø ‡§¨‡•Å‡§≤‡•á‡§ü‡•á‡§°/‡§ï‡•ç‡§∞‡§Æ‡§æ‡§Ç‡§ï‡§ø‡§§ ‡§∏‡•Ç‡§ö‡•Ä‡§∏‡§π ‡§∏‡•ç‡§µ‡§∞‡•Ç‡§™‡§®‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Æ‡§æ‡§∞‡•ç‡§ï‡§°‡§æ‡§â‡§® ‡§µ‡§æ‡§™‡§∞‡§æ.**
    ‡§®‡•á‡§π‡§Æ‡•Ä ‡§Ü‡§¶‡§∞‡§™‡•Ç‡§∞‡•ç‡§£ ‡§Ü‡§£‡§ø ‡§∏‡§π‡§æ‡§Ø‡•ç‡§Ø‡§ï ‡§∞‡§π‡§æ."""
}

# In-memory storage for chat sessions
chat_sessions = {}

@app.route('/')
def index():
    """Render the main chat interface."""
    return render_template('index.html')

@app.route('/get_response', methods=['POST'])
def get_response():
    """Handle chat messages and stream bot responses back to the client."""
    try:
        user_message = request.form.get('message', '').strip()
        language = request.form.get('language', 'en')
        
        if not user_message:
            return Response("Error: No message provided.", status=400)

        # Use the user's IP address as a simple session identifier
        session_id = request.remote_addr
        
        if session_id not in chat_sessions:
            chat_sessions[session_id] = {}
        
        # Create a new chat session for a new language conversation
        if language not in chat_sessions[session_id]:
            system_prompt = SYSTEM_PROMPTS.get(language, SYSTEM_PROMPTS['en'])
            chat = model.start_chat(history=[
                {'role': 'user', 'parts': [system_prompt]},
                {'role': 'model', 'parts': ["Yes, I am Kisan Sathi. I am ready to help."]}
            ])
            chat_sessions[session_id][language] = chat

        chat = chat_sessions[session_id][language]
        
        def stream_generator():
            """A generator function that yields response chunks."""
            try:
                # Use stream=True to get a streaming response
                response_stream = chat.send_message(user_message, stream=True)
                for chunk in response_stream:
                    if chunk.text:
                        # Format as a Server-Sent Event (SSE)
                        data = {'token': chunk.text}
                        yield f"data: {json.dumps(data)}\n\n"
            except Exception as e:
                print(f"Error during stream generation: {e}")
                error_data = {'error': 'An error occurred while generating the response.'}
                yield f"data: {json.dumps(error_data)}\n\n"

        # Return a streaming response
        return Response(stream_generator(), mimetype='text/event-stream')

    except Exception as e:
        print(f"Error in /get_response endpoint: {e}")
        return Response("An internal server error occurred.", status=500)

@app.route('/clear_history', methods=['POST'])
def clear_history():
    """Clear chat history for the current user's session."""
    try:
        session_id = request.remote_addr
        if session_id in chat_sessions:
            chat_sessions.pop(session_id, None)
        return jsonify({'status': 'success', 'message': 'Chat history cleared'})
    except Exception as e:
        print(f"Error in /clear_history: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

if __name__ == '__main__':
    print("üåæ Starting Kisan Sathi ChatBot...")
    print("üìç Server running at: http://127.0.0.1:5000")
    print("‚úÖ Press CTRL+C to stop the server")
    app.run(debug=True, host='0.0.0.0', port=5000)